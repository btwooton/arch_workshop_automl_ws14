{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e7feb5a2",
      "metadata": {
        "id": "e7feb5a2"
      },
      "source": [
        "# WS 12 AutoML with AutoGluon Hands on Module"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gKRURZHj11-T",
      "metadata": {
        "id": "gKRURZHj11-T"
      },
      "source": [
        "\n",
        "## 1. Introduction\n",
        "In this hands on module, we will see how to simplify the process of training high-quality, optimized machine learning models on sample datasets from UCI Machine Learning repository using the [AutoGluon](https://auto.gluon.ai/stable/index.html) package."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NiMElLZy24Zn",
      "metadata": {
        "id": "NiMElLZy24Zn"
      },
      "source": [
        "## 2. Dataset introduction and loading data from UCI ML Repository\n",
        "Now we import pacakges and load in the following three healthcare related datasets from [UCI Machine Learning Repository](https://archive.ics.uci.edu/)\n",
        "\n",
        "\n",
        "*   [Breast Cancer data](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic) from University of Wisconsin\n",
        "*   [Diabetes data](https://archive.ics.uci.edu/dataset/296/diabetes+130-us+hospitals+for+years+1999-2008) representing ten years of clinical care at 130 US hospitals\n",
        "*  [A Drug reviews](https://archive.ics.uci.edu/dataset/461/drug+review+dataset+druglib+com) dataset providing patient reviews on specific drugs\n",
        "\n",
        "The first two datsets will be used to demonstrate AutoGluon's `TabularPredictor` class and how it enables us to train high-fideltiy ensemble models on data without needing to worry about pre-processing.\n",
        "\n",
        "The third dataset will allow us to explore AutoGluon's `MultiModalPredictor` and how it allows us to train models on plain-text inputs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b62dd5b",
      "metadata": {
        "id": "2b62dd5b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ucimlrepo import fetch_ucirepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YreNspRjV_o1",
      "metadata": {
        "id": "YreNspRjV_o1"
      },
      "outputs": [],
      "source": [
        "# here we fix a random seed for reproducibility purposes\n",
        "np.random.seed(913)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oa0rkUeg5JDh",
      "metadata": {
        "id": "oa0rkUeg5JDh"
      },
      "source": [
        "Now we load in the breast cancer dataset. This dataset contains features that describe the characteristics of cell nuclei present in a digitized image taken from the fine needle aspirate of a breast mass. The labels in the data are binary/two-class, with 'B' representing a benign mass and 'M' representing a malignant mass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eNnlKxMf43u9",
      "metadata": {
        "id": "eNnlKxMf43u9"
      },
      "outputs": [],
      "source": [
        "# now we load in the breast cancer dataset from UCI\n",
        "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = breast_cancer_wisconsin_diagnostic.data.features\n",
        "y = breast_cancer_wisconsin_diagnostic.data.targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PT0a0HTa6U-B",
      "metadata": {
        "id": "PT0a0HTa6U-B"
      },
      "outputs": [],
      "source": [
        "print(breast_cancer_wisconsin_diagnostic.variables)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7hSWikQ8Z8GX",
      "metadata": {
        "id": "7hSWikQ8Z8GX"
      },
      "source": [
        "Here we combine our input features `X` and target labels `y` into a single pandas `DataFrame` to make it easier to work with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vuhB5yTh91__",
      "metadata": {
        "id": "vuhB5yTh91__"
      },
      "outputs": [],
      "source": [
        "breast_cancer_df = X.assign(\n",
        "    Diagnosis=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I9tbb7hb99Ni",
      "metadata": {
        "id": "I9tbb7hb99Ni"
      },
      "outputs": [],
      "source": [
        "breast_cancer_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eKQ2XK0-MWe",
      "metadata": {
        "id": "5eKQ2XK0-MWe"
      },
      "outputs": [],
      "source": [
        "breast_cancer_df['Diagnosis'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VTKvVtP3QstW",
      "metadata": {
        "id": "VTKvVtP3QstW"
      },
      "source": [
        "Next we load in the Diabetes dataset. This dataset was constructed with the goal of predicting the early readmission of diabetes patients within 30 days of discharge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3nILN1VRAYE",
      "metadata": {
        "id": "c3nILN1VRAYE"
      },
      "outputs": [],
      "source": [
        "# fetch dataset\n",
        "diabetes_data = fetch_ucirepo(id=296)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = diabetes_data.data.features\n",
        "y = diabetes_data.data.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x4y6ROy8RG9q",
      "metadata": {
        "id": "x4y6ROy8RG9q"
      },
      "outputs": [],
      "source": [
        "print(diabetes_data.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abIT4UzIEG92",
      "metadata": {
        "id": "abIT4UzIEG92"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9qp3Gza3aJPM",
      "metadata": {
        "id": "9qp3Gza3aJPM"
      },
      "source": [
        "Here we combine the input features X and targets y into a single `DataFrame`. We also convert the multi-class readmission labels as follows.\n",
        "1. Original label `'NO'` for \"no readmission\" -> `0`\n",
        "2. Original label `'>30'` for \"admitted in more than 30 days\" -> `1`\n",
        "3. Original label `'<30'` for \"admitted within 30 days\" -> `1`\n",
        "This is done for purely pedagogical purposes so we can demonstrate how to calibrate a model's classification threshold using AutoGluon. AutoGluon is perfectly capable of handling multi-class targets, but converting to binary makes the example simpler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JKzx07jxRMhH",
      "metadata": {
        "id": "JKzx07jxRMhH"
      },
      "outputs": [],
      "source": [
        "diabetes_df = X.assign(\n",
        "    readmitted=y.map(lambda readmit: 0 if readmit == 'NO' else 1) # convert to a binary target\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Oe1LpCMARRBq",
      "metadata": {
        "id": "Oe1LpCMARRBq"
      },
      "outputs": [],
      "source": [
        "diabetes_df['readmitted'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mrU5M0jha7nZ",
      "metadata": {
        "id": "mrU5M0jha7nZ"
      },
      "source": [
        "Since this is a relatively large dataset, for performance reasons, we downsample to only include 20% of the original dataset in our subsequent examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1JRJNviEOcg",
      "metadata": {
        "id": "b1JRJNviEOcg"
      },
      "outputs": [],
      "source": [
        "# because this is such a large dataset, we will down-sample this to only include 20% of the dat\n",
        "diabetes_df_downsamp = diabetes_df.sample(frac=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HrIE7YB7EV_s",
      "metadata": {
        "id": "HrIE7YB7EV_s"
      },
      "outputs": [],
      "source": [
        "diabetes_df_downsamp['readmitted'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PciRQPzH639S",
      "metadata": {
        "id": "PciRQPzH639S"
      },
      "source": [
        "Now we split the two datasets into 80%/20% training/test set splits, so that we can evaluate our tuned models at the very end on unseen test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MDdZzW2OSvmO",
      "metadata": {
        "id": "MDdZzW2OSvmO"
      },
      "outputs": [],
      "source": [
        "bc_train = breast_cancer_df.sample(frac=0.8)\n",
        "bc_test = breast_cancer_df.drop(bc_train.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N7UATHpSS3Og",
      "metadata": {
        "id": "N7UATHpSS3Og"
      },
      "outputs": [],
      "source": [
        "bc_train['Diagnosis'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wA7YrbzcS5-v",
      "metadata": {
        "id": "wA7YrbzcS5-v"
      },
      "outputs": [],
      "source": [
        "bc_test['Diagnosis'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UhxSy-bTTGJi",
      "metadata": {
        "id": "UhxSy-bTTGJi"
      },
      "outputs": [],
      "source": [
        "diabetes_train = diabetes_df_downsamp.sample(frac=0.8)\n",
        "diabetes_test = diabetes_df_downsamp.drop(diabetes_train.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FNIVuqVDTOBR",
      "metadata": {
        "id": "FNIVuqVDTOBR"
      },
      "outputs": [],
      "source": [
        "diabetes_train['readmitted'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sCAS2hIwTQcf",
      "metadata": {
        "id": "sCAS2hIwTQcf"
      },
      "outputs": [],
      "source": [
        "diabetes_test['readmitted'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09Bv3a8n8ZsE",
      "metadata": {
        "id": "09Bv3a8n8ZsE"
      },
      "source": [
        "## 3. Introduction to AutoGluon Tabular Predictor\n",
        "Now we will see how AutoGluon's `TabularPredictor` class can be used to automatically fit a weighted ensemble on the breast cancer dataset, with automatic K-fold cross validation, bagging, and stacking, and with a large suite of models evaluated for inclusion in the final ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SlqyUWsF8nje",
      "metadata": {
        "id": "SlqyUWsF8nje"
      },
      "outputs": [],
      "source": [
        "from autogluon.tabular import TabularPredictor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gmXSmsnXbE8p",
      "metadata": {
        "id": "gmXSmsnXbE8p"
      },
      "source": [
        "Here we construct a `TabularPredictor` by calling its constructor, and specifying the name of the column containing our labels/targets, as well as the evaluation metric we want AutoGluon to use to score the models that it tests for inclusion in its final ensemble. Here we choose `'roc_auc'` for AUROC (or Area Under the ROC curve) which is a good default metric to use for binary classification problems, as it is robust to class imbalances.\n",
        "\n",
        "We then call the `.fit()` method on the `TabularPredictor` and pass it our training data, and two more parameters\n",
        "1. `num_bag_folds` - The number of data folds used in model bagging and K-fold cross validation. According to the AutoGluon documentation, this increases training time by a factor of k\n",
        "2. `exluded_model_types` - Allows us to specify models to leave out of the leaderboard training and ensemble model for faster training time. Here we exluce Neural network models and CatBoost, which can take longer to train than our other models. Feel free to comment out/delete this line if you would prefer to train an ensemble that includes these models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M2uLil1SFC9d",
      "metadata": {
        "id": "M2uLil1SFC9d"
      },
      "outputs": [],
      "source": [
        "# here we do the same with the breast cancer dataset\n",
        "predictor_bc = TabularPredictor( # construct the predictor\n",
        "    label='Diagnosis', eval_metric='roc_auc'\n",
        ").fit( # call the fit method\n",
        "    bc_train,\n",
        "    num_bag_folds=3,\n",
        "    excluded_model_types=['NN_TORCH', 'FASTAI', 'CAT'] # exclude neural nets and CatBoost for faster training\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99nr-eqHcK1Y",
      "metadata": {
        "id": "99nr-eqHcK1Y"
      },
      "source": [
        "After fitting our model, we can then call `.evaluate()` to see how it performs on the held out test data. We can also call the `.leaderboard()` method to see a breakdown of performance across the various models trained and evaluated in the ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K3ElcsjwGjfD",
      "metadata": {
        "id": "K3ElcsjwGjfD"
      },
      "outputs": [],
      "source": [
        "# Now we evaluate the Breast Cancer model on the test data\n",
        "predictor_bc.evaluate(bc_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30NG2xkScdV0",
      "metadata": {
        "id": "30NG2xkScdV0"
      },
      "outputs": [],
      "source": [
        "# Output summary of information about models produced during fit() as a pd.DataFrame. Includes information on test and validation scores for all models, model training times, inference times, and stack levels\n",
        "predictor_bc.leaderboard(bc_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jD-1EZFFGwsv",
      "metadata": {
        "id": "jD-1EZFFGwsv"
      },
      "source": [
        "## 4. Comparison with Scikit Learn Toy Implementation of Bagging + Stacking\n",
        "We see that our accuracy and precision rival that of the benchmark models listed on the UCI Machine Learning repository page for this dataset.\n",
        "\n",
        "\n",
        "Now, for illustrative purposes, we will take a brief look at how much code it would take to implement a similar *(highly simplified)* k-fold bagging + stacking model ensembling such as what AutoGluon does automatically using Scikit Learn, another popular machine learning framework for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7rHfS2Z7V9Tm",
      "metadata": {
        "id": "7rHfS2Z7V9Tm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from xgboost import XGBClassifier\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m1ENeFkuWe0k",
      "metadata": {
        "id": "m1ENeFkuWe0k"
      },
      "outputs": [],
      "source": [
        "# our target labels are text character 'M' and 'B'\n",
        "# Scikit-learn binary classifiers need these to be converted to numeric 1/0\n",
        "bc_train_binary = bc_train.assign(\n",
        "    binary_label=lambda x: x['Diagnosis'].map(lambda diag: 1 if diag == 'M' else 0)\n",
        ").drop(columns='Diagnosis')\n",
        "bc_test_binary = bc_test.assign(\n",
        "    binary_label=lambda x: x['Diagnosis'].map(lambda diag: 1 if diag == 'M' else 0)\n",
        ").drop(columns='Diagnosis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tgH2TZ5PWHfD",
      "metadata": {
        "id": "tgH2TZ5PWHfD"
      },
      "outputs": [],
      "source": [
        "# separate features X from targets y\n",
        "X = bc_train_binary.drop(columns=['binary_label'])\n",
        "y = bc_train_binary['binary_label']\n",
        "# initialize the Kfold object for doing kfold cross validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# construct arrays for storing the out of fold prediciotns for the models\n",
        "oof_preds_rf = np.zeros(len(X))\n",
        "oof_preds_xgb = np.zeros(len(X))\n",
        "\n",
        "# save the bagged models in lists\n",
        "\n",
        "# specifiy the classifiers that will be in each layer\n",
        "layers = [RandomForestClassifier, XGBClassifier]\n",
        "layer_preds = [oof_preds_rf, oof_preds_xgb]\n",
        "layer_bags = [list(), list()]\n",
        "# loop over our layers\n",
        "for i, layer in enumerate(layers):\n",
        "  print(f\"Performing k-fold cross validation at layer {i} with {layer}\")\n",
        "  # do the K-fold cross validation loop\n",
        "  for train_idx, val_idx in tqdm(kf.split(X), total=5):\n",
        "      # split inputs and outputs into training and validation\n",
        "      X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "      y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "      # if we are in a layer past the first layer, the inputs need to include\n",
        "      # the predictions from the prior layer\n",
        "      if i > 0:\n",
        "        X_train = np.column_stack([\n",
        "            X_train.to_numpy(),\n",
        "            layer_preds[i-1][train_idx] # include preds from prior layer\n",
        "        ])\n",
        "        X_val = np.column_stack([\n",
        "            X_val.to_numpy(),\n",
        "            layer_preds[i-1][val_idx]\n",
        "        ])\n",
        "\n",
        "      # fit a model from the given layer on the training fold\n",
        "      model = layer()\n",
        "      model.fit(X_train, y_train)\n",
        "      # evaluate it on the validation fold and save oof predictions\n",
        "      layer_preds[i][val_idx] = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "      # save the model in our layer bag\n",
        "      layer_bags[i].append(model)\n",
        "\n",
        "# final meta model: Weighted ensemble of the predictions from the prior layers\n",
        "meta_features = np.column_stack(layer_preds)\n",
        "\n",
        "meta_model = LogisticRegression()\n",
        "meta_model.fit(meta_features, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74LPiyADbaz7",
      "metadata": {
        "id": "74LPiyADbaz7"
      },
      "source": [
        "Now to evaluate this custom Meta model on the unseen test data, we need to\n",
        "\n",
        "\n",
        "1.   Get 5 separate sets of predictions from each Random Forest model in the first layer\n",
        "2.   Get 5 separate sets of predictions from each XGBoost model in the second layer, appending the predictions from the first layer models as feature inputs to the second layer models\n",
        "3. Average the predicions made at each layer into a single set of predictions per layer\n",
        "4. Append these two sets of predictions together into the final features to feed to the Meta Model (Logistic Regression)\n",
        "5. Get the final predictions from the Meta Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m5xTfZBVbBE8",
      "metadata": {
        "id": "m5xTfZBVbBE8"
      },
      "outputs": [],
      "source": [
        "X_test = bc_test_binary.drop(columns=['binary_label'])\n",
        "y_test = bc_test_binary['binary_label']\n",
        "\n",
        "layer_preds_test = []\n",
        "\n",
        "# steps 1 and 2 - Getting separate predictions from models in each layer\n",
        "for i in range(len(layer_bags)):\n",
        "  # concatenate predictions from prior layer to features if needed\n",
        "  if i > 0:\n",
        "    X_test_stacked = np.column_stack([X_test.to_numpy(), layer_preds_test[i-1]])\n",
        "  else:\n",
        "    X_test_stacked = X_test\n",
        "\n",
        "  # step 3 - compute average predictions across all models in the layer\n",
        "  current_layer_preds = sum([\n",
        "      model.predict_proba(X_test_stacked)[:, 1]\n",
        "      for model in layer_bags[i]\n",
        "  ]) / len(layer_bags[i])\n",
        "\n",
        "  # save the predictions for the layer\n",
        "  layer_preds_test.append(current_layer_preds)\n",
        "\n",
        "# Step 4 - concatenate layer predicitons\n",
        "meta_features_test = np.column_stack(layer_preds_test)\n",
        "\n",
        "# Step 5 - get final predictions\n",
        "final_predictions = meta_model.predict(meta_features_test)\n",
        "\n",
        "# get the accuracy and f1 score\n",
        "print(f\"F1: {f1_score(y_test, final_predictions)}\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, final_predictions)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i_3rXJganwrt",
      "metadata": {
        "id": "i_3rXJganwrt"
      },
      "source": [
        "## 5. Applying AutoGluon to a more complex dataset and threshold tuning\n",
        "We can see that a considerable amount of code, understanding, and index manipulation was required in order to get an ensemble implementation using Scikit-learn that approaches the functionality which AutoGluon provides in only 3-4 lines of code. The toy implementation above also does not perform any greedy model weighting or pruning of models, and only incorporated two model families in the ensemble.\n",
        "\n",
        "Here we train another TabularPredictor on the Diabetes readmission data, to assess how well it scales to larger datasets with heterogeneous input types. Here we will also see how one can tune the decision threshold of a binary classifier with AutoGluon in order to try and achieve better Recall and performance on the positive class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PSoqCnOioqqx",
      "metadata": {
        "id": "PSoqCnOioqqx"
      },
      "outputs": [],
      "source": [
        "diabetes_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V_lHDvBJo8v9",
      "metadata": {
        "id": "V_lHDvBJo8v9"
      },
      "outputs": [],
      "source": [
        "predictor_diabetes = TabularPredictor( # construct the predictor\n",
        "    label='readmitted', eval_metric='roc_auc'\n",
        ").fit( # call the fit method\n",
        "    train_data=diabetes_train,\n",
        "    excluded_model_types=['NN_TORCH', 'FASTAI', 'CAT'], # excluding neural nets for faster training\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hyuN8Cl1pbaS",
      "metadata": {
        "id": "hyuN8Cl1pbaS"
      },
      "outputs": [],
      "source": [
        "predictor_diabetes.evaluate(diabetes_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NzoSVhKyKPPd",
      "metadata": {
        "id": "NzoSVhKyKPPd"
      },
      "source": [
        "The recall of 0.54 tells us that only ~54% of patients who were readmitted to a hospital were successfully classified as such by our model. If we want to tune our classification threshold to achieve a better recall/sensitivity/TPR (true-positive rate), as we often do when working with medical data and developing tests for the presence of risks/conditions, AutoGluon makes this very easy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kDdTjYFE0ptL",
      "metadata": {
        "id": "kDdTjYFE0ptL"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PXnNRZAEK3Mu",
      "metadata": {
        "id": "PXnNRZAEK3Mu"
      },
      "outputs": [],
      "source": [
        "diabetes_preds = predictor_diabetes.predict(diabetes_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_tVwXKJvK5fR",
      "metadata": {
        "id": "_tVwXKJvK5fR"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(diabetes_test['readmitted'], diabetes_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qTXQon333ODy",
      "metadata": {
        "id": "qTXQon333ODy"
      },
      "outputs": [],
      "source": [
        "# now we calibrate the decision threshold of our model, using the F1 score as the calibration metric\n",
        "threshold = predictor_diabetes.calibrate_decision_threshold(metric='f1')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VcgRghAoJ4jJ",
      "metadata": {
        "id": "VcgRghAoJ4jJ"
      },
      "source": [
        "Conceptual Question - Why did we calibrate the decision threshold to optimize the [F1 score](https://en.wikipedia.org/wiki/F-score) (the harmonic mean of precision and recall) if our goal was to achieve higher recall? Why not just use recall as the calibration metric directly?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VQ2tMTzZ3ZNm",
      "metadata": {
        "id": "VQ2tMTzZ3ZNm"
      },
      "outputs": [],
      "source": [
        "predictor_diabetes.set_decision_threshold(threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C3B1v1HJ3e0q",
      "metadata": {
        "id": "C3B1v1HJ3e0q"
      },
      "outputs": [],
      "source": [
        "predictor_diabetes.evaluate(diabetes_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dD7xNZvbLI6A",
      "metadata": {
        "id": "dD7xNZvbLI6A"
      },
      "outputs": [],
      "source": [
        "diabetes_preds = predictor_diabetes.predict(diabetes_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D-luEmxALJl9",
      "metadata": {
        "id": "D-luEmxALJl9"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(diabetes_test['readmitted'], diabetes_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fzxUGnHpLq6v",
      "metadata": {
        "id": "fzxUGnHpLq6v"
      },
      "source": [
        "\n",
        "## 6. Tackling a Text Classification Problem with AutoGluon Tabular and MultiModal\n",
        "Now that we will see how AutoGluon can also seamlessly tackle plain-text columns, such as written reviews, using both the `TabularPredictor` class, as well as the more sophisticated `MultiModalPredictor` which trains a full transformer neural network to make predictions on text-based data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-FbgZFX4ME97",
      "metadata": {
        "id": "-FbgZFX4ME97"
      },
      "outputs": [],
      "source": [
        "from autogluon.multimodal import MultiModalPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MzzX1RXVMIOs",
      "metadata": {
        "id": "MzzX1RXVMIOs"
      },
      "outputs": [],
      "source": [
        "# now we load in the Drug Reviews dataset from UCI Machine learning repository\n",
        "drug_reviews_druglib_com = fetch_ucirepo(id=461)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = drug_reviews_druglib_com.data.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "agG-ZW5kMZ2G",
      "metadata": {
        "id": "agG-ZW5kMZ2G"
      },
      "outputs": [],
      "source": [
        "print(drug_reviews_druglib_com.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0x5UliUVNnyS",
      "metadata": {
        "id": "0x5UliUVNnyS"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QhrSSYhwNV7A",
      "metadata": {
        "id": "QhrSSYhwNV7A"
      },
      "outputs": [],
      "source": [
        "# construct a 3-class label based on the numeric rating from 1-10\n",
        "targets = X['rating'].map(lambda rating: 'positive' if rating >= 7 else 'neutral' if rating >= 4 else 'negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QkhjhDZHMh44",
      "metadata": {
        "id": "QkhjhDZHMh44"
      },
      "outputs": [],
      "source": [
        "drug_reviews_df = X[['benefitsReview', 'sideEffectsReview', 'commentsReview']].assign(\n",
        "    target=targets\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EkDaaqnINkSH",
      "metadata": {
        "id": "EkDaaqnINkSH"
      },
      "outputs": [],
      "source": [
        "drug_reviews_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TfRMVoM5Nzv6",
      "metadata": {
        "id": "TfRMVoM5Nzv6"
      },
      "outputs": [],
      "source": [
        "drug_reviews_df['target'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bqfaVdGCRv4S",
      "metadata": {
        "id": "bqfaVdGCRv4S"
      },
      "outputs": [],
      "source": [
        "# we will downsample the three classes to achieve a smaller dataset for demonstration purposes\n",
        "drug_reviews_downsamp = pd.concat([\n",
        "    drug_reviews_df.query('target == \"positive\"').sample(n=400),\n",
        "    drug_reviews_df.query('target == \"neutral\"').sample(n=400),\n",
        "    drug_reviews_df.query('target == \"negative\"').sample(n=400)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "piD3hOA9N9LI",
      "metadata": {
        "id": "piD3hOA9N9LI"
      },
      "outputs": [],
      "source": [
        "drug_reviews_train = drug_reviews_downsamp.sample(frac=0.8)\n",
        "drug_reviews_test = drug_reviews_downsamp.drop(drug_reviews_train.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jSmiNc8ROGkt",
      "metadata": {
        "id": "jSmiNc8ROGkt"
      },
      "outputs": [],
      "source": [
        "drug_reviews_train['target'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BrV0BoeZOJ7R",
      "metadata": {
        "id": "BrV0BoeZOJ7R"
      },
      "outputs": [],
      "source": [
        "drug_reviews_test['target'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y7drEuRnkNpX",
      "metadata": {
        "id": "y7drEuRnkNpX"
      },
      "outputs": [],
      "source": [
        "# first we fit a TabularPredictor to the dataset to see how it performs\n",
        "predictor_tab = TabularPredictor(label='target', eval_metric='acc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3JU2KY68kVSr",
      "metadata": {
        "id": "3JU2KY68kVSr"
      },
      "outputs": [],
      "source": [
        "predictor_tab.fit(drug_reviews_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S98glnhPku_c",
      "metadata": {
        "id": "S98glnhPku_c"
      },
      "outputs": [],
      "source": [
        "# now we evaluate the model's performance on the test data\n",
        "predictor_tab.evaluate(drug_reviews_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tRKokVu8k_2f",
      "metadata": {
        "id": "tRKokVu8k_2f"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(drug_reviews_test['target'], predictor_tab.predict(drug_reviews_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pC6M7ckqlMSD",
      "metadata": {
        "id": "pC6M7ckqlMSD"
      },
      "outputs": [],
      "source": [
        "print(classification_report(drug_reviews_test['target'], predictor_tab.predict(drug_reviews_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pG79RvWoMjqf",
      "metadata": {
        "id": "pG79RvWoMjqf"
      },
      "outputs": [],
      "source": [
        "# now we construct our model using the MultiModalPredictor class\n",
        "predictor = MultiModalPredictor(label='target', eval_metric='acc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j2YJz2zmlcIR",
      "metadata": {
        "id": "j2YJz2zmlcIR"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del(predictor_tab)\n",
        "del(predictor_bc)\n",
        "del(predictor_diabetes)\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4lOV16w7N6S8",
      "metadata": {
        "id": "4lOV16w7N6S8"
      },
      "outputs": [],
      "source": [
        "predictor.fit(drug_reviews_train, time_limit=180)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bmi_dGhiOS8E",
      "metadata": {
        "id": "Bmi_dGhiOS8E"
      },
      "outputs": [],
      "source": [
        "predictor.evaluate(drug_reviews_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H4yab23DRYfr",
      "metadata": {
        "id": "H4yab23DRYfr"
      },
      "outputs": [],
      "source": [
        "predictions = predictor.predict(drug_reviews_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eNG1EBbXRpIv",
      "metadata": {
        "id": "eNG1EBbXRpIv"
      },
      "outputs": [],
      "source": [
        "predictions.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sJiB0D3OTrl9",
      "metadata": {
        "id": "sJiB0D3OTrl9"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(drug_reviews_test['target'], predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E4S4_mn5UsJR",
      "metadata": {
        "id": "E4S4_mn5UsJR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
