{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e7feb5a2",
      "metadata": {
        "id": "e7feb5a2"
      },
      "source": [
        "# WS 12 AutoML with AutoGluon Hands on Module"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by pip installing the `utogluon` and `ucimlrepo` packages"
      ],
      "metadata": {
        "id": "gKRURZHj11-T"
      },
      "id": "gKRURZHj11-T"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogluon\n",
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn8m61eN2BSJ",
        "outputId": "0f985355-7819-4ea2-eb9b-855cf1e46be1"
      },
      "id": "Dn8m61eN2BSJ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon\n",
            "  Downloading autogluon-1.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.core==1.5.0 (from autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading autogluon_core-1.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting autogluon.features==1.5.0 (from autogluon)\n",
            "  Downloading autogluon_features-1.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.tabular==1.5.0 (from autogluon.tabular[all]==1.5.0->autogluon)\n",
            "  Downloading autogluon_tabular-1.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting autogluon.multimodal==1.5.0 (from autogluon)\n",
            "  Downloading autogluon_multimodal-1.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting autogluon.timeseries==1.5.0 (from autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading autogluon_timeseries-1.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2.4.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (2.0.2)\n",
            "Requirement already satisfied: scipy<1.17,>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn<1.8.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (1.6.1)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (3.6.1)\n",
            "Requirement already satisfied: pandas<2.4.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (2.2.2)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (4.67.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (2.32.4)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (3.10.0)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading boto3-1.42.46-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting autogluon.common==1.5.0 (from autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading autogluon_common-1.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting ray<2.53,>=2.43.0 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.core[all]==1.5.0->autogluon) (18.1.0)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from autogluon.core[all]==1.5.0->autogluon) (0.2.7)\n",
            "Collecting stevedore<5.5 (from autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: Pillow<12,>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.5.0->autogluon) (11.3.0)\n",
            "Requirement already satisfied: torch<2.10,>=2.6 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.5.0->autogluon) (2.9.0+cpu)\n",
            "Collecting lightning<2.6,>=2.5.1 (from autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading lightning-2.5.6-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers<4.58,>=4.51.0 (from transformers[sentencepiece]<4.58,>=4.51.0->autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate<2.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.5.0->autogluon) (1.12.0)\n",
            "Requirement already satisfied: fsspec<=2025.3 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon) (2025.3.0)\n",
            "Collecting jsonschema<4.24,>=4.18 (from autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision<0.25.0,>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.5.0->autogluon) (0.24.0+cpu)\n",
            "Requirement already satisfied: scikit-image<0.26.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.5.0->autogluon) (0.25.2)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.5.0->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.8,>=1.2.0 (from autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: omegaconf<2.4.0,>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.5.0->autogluon) (2.3.0)\n",
            "Collecting pytorch-metric-learning<2.9,>=1.3.0 (from autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: nltk<3.10,>=3.4.5 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.5.0->autogluon) (3.9.1)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.5.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.5.0->autogluon) (3.1.6)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.multimodal==1.5.0->autogluon) (2.19.0)\n",
            "Collecting pytesseract<0.4,>=0.3.9 (from autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py3<8.0,>=7.352.0 (from autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting einx (from autogluon.tabular[all]==1.5.0->autogluon)\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: lightgbm<4.7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon) (4.6.0)\n",
            "Collecting huggingface_hub<1.0 (from huggingface_hub[torch]<1.0; extra == \"all\"->autogluon.tabular[all]==1.5.0->autogluon)\n",
            "  Downloading huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: xgboost<3.2,>=2.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon) (3.1.3)\n",
            "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.5.0->autogluon)\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: fastai<2.9,>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon) (2.8.6)\n",
            "Collecting loguru (from autogluon.tabular[all]==1.5.0->autogluon)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: einops<0.9,>=0.7 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon) (0.8.2)\n",
            "Requirement already satisfied: spacy<3.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.tabular[all]==1.5.0->autogluon) (3.8.11)\n",
            "Requirement already satisfied: joblib<1.7,>=1.2 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (1.5.3)\n",
            "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading gluonts-0.16.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
            "Collecting mlforecast<0.15.0,>=0.14.0 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading mlforecast-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting utilsforecast<0.2.12,>=0.2.3 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading utilsforecast-0.2.11-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting coreforecast<0.0.17,>=0.0.12 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading fugue-0.9.6-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: orjson~=3.9 in /usr/local/lib/python3.12/dist-packages (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (3.11.7)\n",
            "Collecting chronos-forecasting<2.4,>=2.2.2 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading chronos_forecasting-2.2.2-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting peft<0.18,>=0.13.0 (from autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading peft-0.17.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: psutil<7.2.0,>=5.7.3 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (5.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.0 in /usr/local/lib/python3.12/dist-packages (from autogluon.common==1.5.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (6.0.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.5.0->autogluon) (26.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.5.0->autogluon) (0.7.0)\n",
            "Collecting botocore<1.43.0,>=1.42.46 (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading botocore-1.42.46-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading jmespath-1.1.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.17.0,>=0.16.0 (from boto3<2,>=1.10->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.5.0->autogluon) (0.21)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.5.0->autogluon) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.5.0->autogluon) (1.17.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon) (4.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.5.0->autogluon) (0.70.16)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (24.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (1.12.11)\n",
            "Requirement already satisfied: fasttransform>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (0.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (1.1.3)\n",
            "Requirement already satisfied: plum-dispatch in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (2.6.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (3.1.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon) (3.13.3)\n",
            "Collecting triad>=1.0.0 (from fugue>=0.9.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading triad-1.0.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting adagio>=0.2.6 (from fugue>=0.9.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (2.12.3)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1.0->huggingface_hub[torch]<1.0; extra == \"all\"->autogluon.tabular[all]==1.5.0->autogluon) (3.20.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1.0->huggingface_hub[torch]<1.0; extra == \"all\"->autogluon.tabular[all]==1.5.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.5.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.12/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.5.0->autogluon) (0.10.9.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.5.0->autogluon) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.5.0->autogluon) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.5.0->autogluon) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.5.0->autogluon) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.5.0->autogluon) (0.30.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.6,>=2.5.1->autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pytorch-lightning (from lightning<2.6,>=2.5.1->autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading pytorch_lightning-2.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (2.9.0.post0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (0.60.0)\n",
            "Collecting optuna (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading optuna-4.7.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting window-ops (from mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.5.0->autogluon) (5.2.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.5.0->autogluon) (8.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.5.0->autogluon) (2025.11.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.5.0->autogluon) (4.9.3)\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon) (13.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon) (0.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.4.0,>=2.0.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (2025.3)\n",
            "Collecting click (from nltk<3.10,>=3.4.5->autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray<2.53,>=2.43.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from ray<2.53,>=2.43.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (5.29.6)\n",
            "Collecting aiohttp_cors (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading colorful-0.5.8-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting py-spy>=0.4.0 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (510 bytes)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (1.76.0)\n",
            "Collecting opencensus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (1.38.0)\n",
            "Collecting opentelemetry-exporter-prometheus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.60b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-proto in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (1.38.0)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (0.24.1)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.12/dist-packages (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (7.5.0)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading virtualenv-20.36.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (2026.1.4)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.5.0->autogluon) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.5.0->autogluon) (2026.1.28)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.5.0->autogluon) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<1.8.0,>=1.4.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (0.21.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (75.2.0)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (0.14.6)\n",
            "Collecting pbr>=2.0.0 (from stevedore<5.5->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading pbr-7.0.3-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.5.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.5.0->autogluon) (3.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.5.0->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.5.0->autogluon) (3.1.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon) (1.14.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<4.58,>=4.51.0->transformers[sentencepiece]<4.58,>=4.51.0->autogluon.multimodal==1.5.0->autogluon) (0.22.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.12/dist-packages (from transformers[sentencepiece]<4.58,>=4.51.0->autogluon.multimodal==1.5.0->autogluon) (0.2.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost<3.2,>=2.0->autogluon.tabular[all]==1.5.0->autogluon) (2.29.3)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx->autogluon.tabular[all]==1.5.0->autogluon) (2.4.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3->autogluon.multimodal==1.5.0->autogluon) (1.22.0)\n",
            "Requirement already satisfied: python-fasthtml>=0.12.34 in /usr/local/lib/python3.12/dist-packages (from fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (0.12.40)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.5.0->autogluon) (4.13.5)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (0.43.0)\n",
            "Requirement already satisfied: opentelemetry-api==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.30.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.30.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (0.59b0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api==1.38.0->opentelemetry-sdk>=1.30.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (8.7.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (1.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.10,>=2.6->autogluon.multimodal==1.5.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (0.1.5)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (4.5.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy<3.9->autogluon.tabular[all]==1.5.0->autogluon) (0.23.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (2.1.1)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (2.29.0)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading openxlab-0.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting opentelemetry-sdk>=1.30.0 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-exporter-prometheus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.60b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-sdk>=1.30.0 (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading opentelemetry_sdk-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-prometheus (from ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading opentelemetry_exporter_prometheus-0.59b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (1.18.3)\n",
            "Collecting colorlog (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (2.0.46)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.5.0->autogluon) (9.1.3)\n",
            "Requirement already satisfied: beartype>=0.16.2 in /usr/local/lib/python3.12/dist-packages (from plum-dispatch->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (0.22.9)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon) (2.19.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (1.3.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (1.72.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (1.27.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (2.47.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon) (0.1.2)\n",
            "Requirement already satisfied: starlette>0.33 in /usr/local/lib/python3.12/dist-packages (from python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (0.50.0)\n",
            "Requirement already satisfied: oauthlib in /usr/local/lib/python3.12/dist-packages (from python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (3.3.1)\n",
            "Requirement already satisfied: itsdangerous in /usr/local/lib/python3.12/dist-packages (from python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (2.2.0)\n",
            "Requirement already satisfied: uvicorn>=0.30 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.30->python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (0.40.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (0.28.1)\n",
            "Requirement already satisfied: fastlite>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (0.2.4)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (from python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (0.0.22)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna->mlforecast<0.15.0,>=0.14.0->autogluon.timeseries==1.5.0->autogluon.timeseries[all]==1.5.0->autogluon) (3.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.5.0->autogluon) (2.8.3)\n",
            "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytz>=2020.1 (from pandas<2.4.0,>=2.0.0->autogluon.core==1.5.0->autogluon.core[all]==1.5.0->autogluon)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.5.0->autogluon)\n",
            "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.5.0->autogluon) (1.7.1)\n",
            "Requirement already satisfied: apswutils>=0.1.2 in /usr/local/lib/python3.12/dist-packages (from fastlite>=0.1.1->python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (0.1.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api==1.38.0->opentelemetry-sdk>=1.30.0->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (3.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette>0.33->python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (4.12.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.30->uvicorn[standard]>=0.30->python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (0.16.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.30->python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.30->python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (1.2.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.30->python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.30->python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.30->python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (15.0.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (1.0.9)\n",
            "Requirement already satisfied: apsw in /usr/local/lib/python3.12/dist-packages (from apswutils>=0.1.2->fastlite>=0.1.1->python-fasthtml>=0.12.34->fastprogress>=0.2.4->fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.5.0->autogluon) (3.51.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.53,>=2.43.0; (platform_system != \"Windows\" or python_version != \"3.13\") and extra == \"all\"->autogluon.core[all]==1.5.0->autogluon) (0.6.2)\n",
            "Downloading autogluon-1.5.0-py3-none-any.whl (5.9 kB)\n",
            "Downloading autogluon_core-1.5.0-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon_features-1.5.0-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon_multimodal-1.5.0-py3-none-any.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.1/452.1 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon_tabular-1.5.0-py3-none-any.whl (515 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.2/515.2 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon_timeseries-1.5.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon_common-1.5.0-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.42.46-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chronos_forecasting-2.2.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coreforecast-0.0.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fugue-0.9.6-py3-none-any.whl (280 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.8/280.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gluonts-0.16.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.6-py3-none-any.whl (827 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.9/827.9 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlforecast-0.14.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.9/504.9 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.52.1-cp312-cp312-manylinux2014_x86_64.whl (72.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsforecast-2.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (353 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.3/353.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.2.11-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
            "Downloading botocore-1.42.46-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading pbr-7.0.3-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_spy-0.4.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.16.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triad-1.0.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.36.1-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.8-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_exporter_prometheus-0.59b0-py3-none-any.whl (13 kB)\n",
            "Downloading optuna-4.7.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.9/413.9 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.6.1-py3-none-any.whl (857 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.3/857.3 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
            "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3, seqeval\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=03669b69bc5fbd5541400d682ddef050d12a8b1c9ee0e4fd4997808694c4c909\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/65/79/33dee66cba26e8204801916dfee7481bccfd22905ebb841fe5\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=0aa4115efefb2515d3efdf78e24926a3483109d4b9d63410ab1ef0e4b4caa31b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
            "Successfully built nvidia-ml-py3 seqeval\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, distlib, colorful, virtualenv, tensorboardX, pytesseract, pycryptodome, pdf2image, pbr, ordered-set, openxlab, loguru, lightning-utilities, jmespath, coreforecast, colorlog, colorama, click, window-ops, stevedore, model-index, huggingface_hub, einx, botocore, utilsforecast, triad, torchmetrics, seqeval, s3transfer, pytorch-metric-learning, optuna, opendatalab, jsonschema, gluonts, catboost, aiohttp_cors, transformers, timm, ray, pytorch-lightning, openmim, opencensus, nlpaug, mlforecast, boto3, adagio, peft, opentelemetry-exporter-prometheus, lightning, fugue, evaluate, chronos-forecasting, autogluon.common, statsforecast, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface_hub 1.4.0\n",
            "    Uninstalling huggingface_hub-1.4.0:\n",
            "      Successfully uninstalled huggingface_hub-1.4.0\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.26.0\n",
            "    Uninstalling jsonschema-4.26.0:\n",
            "      Successfully uninstalled jsonschema-4.26.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 5.0.0\n",
            "    Uninstalling transformers-5.0.0:\n",
            "      Successfully uninstalled transformers-5.0.0\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.24\n",
            "    Uninstalling timm-1.0.24:\n",
            "      Successfully uninstalled timm-1.0.24\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.18.1\n",
            "    Uninstalling peft-0.18.1:\n",
            "      Successfully uninstalled peft-0.18.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "rasterio 1.5.0 requires click!=8.2.*,>=4.0, but you have click 8.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adagio-0.2.6 aiohttp_cors-0.8.1 autogluon-1.5.0 autogluon.common-1.5.0 autogluon.core-1.5.0 autogluon.features-1.5.0 autogluon.multimodal-1.5.0 autogluon.tabular-1.5.0 autogluon.timeseries-1.5.0 boto3-1.42.46 botocore-1.42.46 catboost-1.2.8 chronos-forecasting-2.2.2 click-8.2.1 colorama-0.4.6 colorful-0.5.8 colorlog-6.10.1 coreforecast-0.0.16 distlib-0.4.0 einx-0.3.0 evaluate-0.4.6 fugue-0.9.6 gluonts-0.16.2 huggingface_hub-0.36.2 jmespath-1.1.0 jsonschema-4.23.0 lightning-2.5.6 lightning-utilities-0.15.2 loguru-0.7.3 mlforecast-0.14.0 model-index-0.1.11 nlpaug-1.1.11 nvidia-ml-py3-7.352.0 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 opentelemetry-exporter-prometheus-0.59b0 openxlab-0.0.11 optuna-4.7.0 ordered-set-4.1.0 pbr-7.0.3 pdf2image-1.17.0 peft-0.17.1 py-spy-0.4.1 pycryptodome-3.23.0 pytesseract-0.3.13 pytorch-lightning-2.6.1 pytorch-metric-learning-2.8.1 ray-2.52.1 s3transfer-0.16.0 seqeval-1.2.2 statsforecast-2.0.1 stevedore-5.4.1 tensorboardX-2.6.4 timm-1.0.3 torchmetrics-1.7.4 transformers-4.57.6 triad-1.0.1 utilsforecast-0.2.11 virtualenv-20.36.1 window-ops-0.0.15\n",
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we import pacakges and load in heart disease data from UCI Machine Learning Repository and the Pima Indian Diabetes Dataset hosted on the github repo"
      ],
      "metadata": {
        "id": "NiMElLZy24Zn"
      },
      "id": "NiMElLZy24Zn"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2b62dd5b",
      "metadata": {
        "id": "2b62dd5b"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from ucimlrepo import fetch_ucirepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cff198e",
      "metadata": {
        "id": "4cff198e"
      },
      "outputs": [],
      "source": [
        "# load in the heart disease dataset from UCI\n",
        "heart_disease = fetch_ucirepo(id=45)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = heart_disease.data.features\n",
        "y = heart_disease.data.targets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# variable information\n",
        "print(heart_disease.variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y78H633V4McN",
        "outputId": "8c983398-a32f-4a58-d90f-067cd62f31d2"
      },
      "id": "Y78H633V4McN",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        name     role         type demographic  \\\n",
            "0        age  Feature      Integer         Age   \n",
            "1        sex  Feature  Categorical         Sex   \n",
            "2         cp  Feature  Categorical        None   \n",
            "3   trestbps  Feature      Integer        None   \n",
            "4       chol  Feature      Integer        None   \n",
            "5        fbs  Feature  Categorical        None   \n",
            "6    restecg  Feature  Categorical        None   \n",
            "7    thalach  Feature      Integer        None   \n",
            "8      exang  Feature  Categorical        None   \n",
            "9    oldpeak  Feature      Integer        None   \n",
            "10     slope  Feature  Categorical        None   \n",
            "11        ca  Feature      Integer        None   \n",
            "12      thal  Feature  Categorical        None   \n",
            "13       num   Target      Integer        None   \n",
            "\n",
            "                                          description  units missing_values  \n",
            "0                                                None  years             no  \n",
            "1                                                None   None             no  \n",
            "2                                                None   None             no  \n",
            "3   resting blood pressure (on admission to the ho...  mm Hg             no  \n",
            "4                                   serum cholestoral  mg/dl             no  \n",
            "5                     fasting blood sugar > 120 mg/dl   None             no  \n",
            "6                                                None   None             no  \n",
            "7                         maximum heart rate achieved   None             no  \n",
            "8                             exercise induced angina   None             no  \n",
            "9   ST depression induced by exercise relative to ...   None             no  \n",
            "10                                               None   None             no  \n",
            "11  number of major vessels (0-3) colored by flour...   None            yes  \n",
            "12                                               None   None            yes  \n",
            "13                         diagnosis of heart disease   None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finalize the heart disease dataset in a single DataFrame with predictors and labels\n",
        "heart_disease_df = X.assign(\n",
        "    binary_label=y.map(lambda value: value > 0).astype(int) # convert categorical labels to binary (1=heart disease, 0=no heart disease)\n",
        ")"
      ],
      "metadata": {
        "id": "YqvU2QZD3uL2"
      },
      "id": "YqvU2QZD3uL2",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load in the diabetes dataset from the GitHub repository\n",
        "diabetes_df = pd.read_csv('https://github.com/btwooton/arch_workshop_automl_ws14/raw/refs/heads/main/data/diabetes.csv')"
      ],
      "metadata": {
        "id": "eNnlKxMf43u9"
      },
      "id": "eNnlKxMf43u9",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PT0a0HTa6U-B",
        "outputId": "ff3ddb8a-faf7-4c6b-97c9-7a80131389ba"
      },
      "id": "PT0a0HTa6U-B",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0              6      148             72             35        0  33.6   \n",
              "1              1       85             66             29        0  26.6   \n",
              "2              8      183             64              0        0  23.3   \n",
              "3              1       89             66             23       94  28.1   \n",
              "4              0      137             40             35      168  43.1   \n",
              "..           ...      ...            ...            ...      ...   ...   \n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                       0.627   50        1  \n",
              "1                       0.351   31        0  \n",
              "2                       0.672   32        1  \n",
              "3                       0.167   21        0  \n",
              "4                       2.288   33        1  \n",
              "..                        ...  ...      ...  \n",
              "763                     0.171   63        0  \n",
              "764                     0.340   27        0  \n",
              "765                     0.245   30        0  \n",
              "766                     0.349   47        1  \n",
              "767                     0.315   23        0  \n",
              "\n",
              "[768 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1a7ea34-a5cf-4e4f-8608-b686ad404823\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1a7ea34-a5cf-4e4f-8608-b686ad404823')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a1a7ea34-a5cf-4e4f-8608-b686ad404823 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a1a7ea34-a5cf-4e4f-8608-b686ad404823');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_a35a1366-b541-4677-aba9-1628e3d663f4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('diabetes_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a35a1366-b541-4677-aba9-1628e3d663f4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('diabetes_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "diabetes_df",
              "summary": "{\n  \"name\": \"diabetes_df\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.8841603203754405,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigreeFunction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33132859501277484,\n        \"min\": 0.078,\n        \"max\": 2.42,\n        \"num_unique_values\": 517,\n        \"samples\": [\n          1.731,\n          0.426,\n          0.138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we split the two datasets into 80%/20% training/test set splits"
      ],
      "metadata": {
        "id": "PciRQPzH639S"
      },
      "id": "PciRQPzH639S"
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the heart disease dataset into training and test sets using DataFrame.sample()\n",
        "hd_train = heart_disease_df.sample(frac=0.8)\n",
        "hd_test = heart_disease_df.drop(hd_train.index)"
      ],
      "metadata": {
        "id": "WPe-3rr867cu"
      },
      "id": "WPe-3rr867cu",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hd_train['binary_label'].value_counts()"
      ],
      "metadata": {
        "id": "uL8bDStN8zsD",
        "outputId": "244b897d-5229-4d19-8413-e09655a0ad62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "id": "uL8bDStN8zsD",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "binary_label\n",
              "0    128\n",
              "1    114\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>binary_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hd_test['binary_label'].value_counts()"
      ],
      "metadata": {
        "id": "oUWhfJy082Zv",
        "outputId": "a2f97ff7-1811-4b6f-8385-453bfe76c862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "id": "oUWhfJy082Zv",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "binary_label\n",
              "0    36\n",
              "1    25\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>binary_label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the diabetes dataset into training and test sets\n",
        "diabetes_train = diabetes_df.sample(frac=0.8)\n",
        "diabetes_test = diabetes_df.drop(diabetes_train.index)"
      ],
      "metadata": {
        "id": "s0b_iDyp7Ia6"
      },
      "id": "s0b_iDyp7Ia6",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_train['Outcome'].value_counts()"
      ],
      "metadata": {
        "id": "tgB-ihYE7xsw",
        "outputId": "dbd0a7c5-69ef-4ec4-873f-ea02f4f3a6df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "id": "tgB-ihYE7xsw",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Outcome\n",
              "0    408\n",
              "1    206\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Outcome</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_test['Outcome'].value_counts()"
      ],
      "metadata": {
        "id": "4eETbt3y70We",
        "outputId": "2d3c0c9e-4b8e-4e62-c8d3-fe240bdb336d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "id": "4eETbt3y70We",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Outcome\n",
              "0    92\n",
              "1    62\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Outcome</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we use AutoGluon's `TabularPredictor` class to fit a weighted ensemble of classifiers on each of the two datasets, which will automatically use the best performing models on Validation data"
      ],
      "metadata": {
        "id": "09Bv3a8n8ZsE"
      },
      "id": "09Bv3a8n8ZsE"
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor"
      ],
      "metadata": {
        "id": "SlqyUWsF8nje"
      },
      "id": "SlqyUWsF8nje",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting a tabular predictor on the Heart Disease Dataset\n",
        "predictor_hd = TabularPredictor(label='binary_label', eval_metric='roc_auc').fit(hd_train)"
      ],
      "metadata": {
        "id": "ZVdjiVDX8k0g",
        "outputId": "c051664f-334a-4b9d-a112-8bd93a4dff81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZVdjiVDX8k0g",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20260210_234907\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.5.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          2\n",
            "Pytorch Version:    2.9.0+cpu\n",
            "CUDA Version:       CUDA is not available\n",
            "Memory Avail:       10.97 GB / 12.67 GB (86.6%)\n",
            "Disk Space Avail:   85.47 GB / 107.72 GB (79.3%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='extreme'  : New in v1.5: The state-of-the-art for tabular data. Massively better than 'best' on datasets <100000 samples by using new Tabular Foundation Models (TFMs) meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, TabDPT, and TabM. Requires a GPU and `pip install autogluon.tabular[tabarena]` to install TabPFN, TabICL, and TabDPT.\n",
            "\tpresets='best'     : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='best_v150': New in v1.5: Better quality than 'best' and 5x+ faster to train. Give it a try!\n",
            "\tpresets='high'     : Strong accuracy with fast inference speed.\n",
            "\tpresets='high_v150': New in v1.5: Better quality than 'high' and 5x+ faster to train. Give it a try!\n",
            "\tpresets='good'     : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'   : Fast training time, ideal for initial prototyping.\n",
            "Using hyperparameters preset: hyperparameters='default'\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20260210_234907\"\n",
            "Train Data Rows:    242\n",
            "Train Data Columns: 13\n",
            "Label Column:       binary_label\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [np.int64(0), np.int64(1)]\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11227.91 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) :  3 | ['oldpeak', 'ca', 'thal']\n",
            "\t\t('int', [])   : 10 | ['age', 'sex', 'cp', 'trestbps', 'chol', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 3 | ['oldpeak', 'ca', 'thal']\n",
            "\t\t('int', [])       : 7 | ['age', 'cp', 'trestbps', 'chol', 'restecg', ...]\n",
            "\t\t('int', ['bool']) : 3 | ['sex', 'fbs', 'exang']\n",
            "\t0.1s = Fit runtime\n",
            "\t13 features in original data used to generate 13 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 193, Val Rows: 49\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/11.0 GB\n",
            "\t0.8796\t = Validation score   (roc_auc)\n",
            "\t3.31s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.9 GB\n",
            "\t0.8813\t = Validation score   (roc_auc)\n",
            "\t0.48s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.8512\t = Validation score   (roc_auc)\n",
            "\t0.82s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.8612\t = Validation score   (roc_auc)\n",
            "\t0.56s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\tFitting with cpus=1, gpus=0\n",
            "\t0.8562\t = Validation score   (roc_auc)\n",
            "\t0.93s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.857\t = Validation score   (roc_auc)\n",
            "\t0.65s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.862\t = Validation score   (roc_auc)\n",
            "\t0.66s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.9 GB\n",
            "No improvement since epoch 3: early stopping\n",
            "\t0.8829\t = Validation score   (roc_auc)\n",
            "\t3.93s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting with cpus=1, gpus=0\n",
            "\t0.8545\t = Validation score   (roc_auc)\n",
            "\t0.2s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.9 GB\n",
            "\t0.8629\t = Validation score   (roc_auc)\n",
            "\t6.73s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
            "\t0.8679\t = Validation score   (roc_auc)\n",
            "\t0.79s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting 1 model on all data | Fitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
            "\tEnsemble Weights: {'NeuralNetFastAI': 0.833, 'CatBoost': 0.167}\n",
            "\t0.8846\t = Validation score   (roc_auc)\n",
            "\t0.05s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 19.83s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1544.1 rows/s (49 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20260210_234907\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_diabetes = TabularPredictor(label='Outcome', eval_metric='roc_auc').fit(diabetes_train)"
      ],
      "metadata": {
        "id": "sKj_Ams69W9p",
        "outputId": "5909064c-0077-4477-827c-930e2586951a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sKj_Ams69W9p",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20260211_000313\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.5.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          2\n",
            "Pytorch Version:    2.9.0+cpu\n",
            "CUDA Version:       CUDA is not available\n",
            "Memory Avail:       10.84 GB / 12.67 GB (85.5%)\n",
            "Disk Space Avail:   85.42 GB / 107.72 GB (79.3%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='extreme'  : New in v1.5: The state-of-the-art for tabular data. Massively better than 'best' on datasets <100000 samples by using new Tabular Foundation Models (TFMs) meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, TabDPT, and TabM. Requires a GPU and `pip install autogluon.tabular[tabarena]` to install TabPFN, TabICL, and TabDPT.\n",
            "\tpresets='best'     : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='best_v150': New in v1.5: Better quality than 'best' and 5x+ faster to train. Give it a try!\n",
            "\tpresets='high'     : Strong accuracy with fast inference speed.\n",
            "\tpresets='high_v150': New in v1.5: Better quality than 'high' and 5x+ faster to train. Give it a try!\n",
            "\tpresets='good'     : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'   : Fast training time, ideal for initial prototyping.\n",
            "Using hyperparameters preset: hyperparameters='default'\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20260211_000313\"\n",
            "Train Data Rows:    614\n",
            "Train Data Columns: 8\n",
            "Label Column:       Outcome\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  [np.int64(0), np.int64(1)]\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11092.09 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['BMI', 'DiabetesPedigreeFunction']\n",
            "\t\t('int', [])   : 6 | ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['BMI', 'DiabetesPedigreeFunction']\n",
            "\t\t('int', [])   : 6 | ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.36s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 491, Val Rows: 123\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.8 GB\n",
            "\t0.8373\t = Validation score   (roc_auc)\n",
            "\t1.76s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.8 GB\n",
            "\t0.8302\t = Validation score   (roc_auc)\n",
            "\t0.73s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.8114\t = Validation score   (roc_auc)\n",
            "\t0.85s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.8236\t = Validation score   (roc_auc)\n",
            "\t0.71s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\tFitting with cpus=1, gpus=0\n",
            "\t0.8308\t = Validation score   (roc_auc)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.8209\t = Validation score   (roc_auc)\n",
            "\t0.6s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.8241\t = Validation score   (roc_auc)\n",
            "\t0.53s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.8 GB\n",
            "\t0.8215\t = Validation score   (roc_auc)\n",
            "\t0.57s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting with cpus=1, gpus=0\n",
            "\t0.8504\t = Validation score   (roc_auc)\n",
            "\t0.18s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.8 GB\n",
            "\t0.8067\t = Validation score   (roc_auc)\n",
            "\t0.91s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.1/10.8 GB\n",
            "\t0.7888\t = Validation score   (roc_auc)\n",
            "\t0.81s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting 1 model on all data | Fitting with cpus=2, gpus=0, mem=0.0/10.8 GB\n",
            "\tEnsemble Weights: {'XGBoost': 0.533, 'CatBoost': 0.267, 'NeuralNetTorch': 0.133, 'NeuralNetFastAI': 0.067}\n",
            "\t0.8537\t = Validation score   (roc_auc)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 9.13s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4706.1 rows/s (123 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20260211_000313\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can refit the predictors on the full training datasets using the refit_full() method to get slightly better performance\n",
        "predictor_hd.refit_full()\n",
        "predictor_diabetes.refit_full()"
      ],
      "metadata": {
        "id": "zn9dRgfyAlbc",
        "outputId": "a1e0cd64-f8a6-4b58-985c-1ef628b0e30c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zn9dRgfyAlbc",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_FULL ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.7 GB\n",
            "\t0.73s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM_FULL ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.7 GB\n",
            "\t0.67s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: RandomForestGini_FULL ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.61s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: RandomForestEntr_FULL ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.6s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: CatBoost_FULL ...\n",
            "\tFitting with cpus=1, gpus=0\n",
            "\t0.03s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: ExtraTreesGini_FULL ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.56s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: ExtraTreesEntr_FULL ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.59s\t = Training   runtime\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: NeuralNetFastAI_FULL ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.7 GB\n",
            "\tStopping at the best epoch learned earlier - 3.\n",
            "\t0.24s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost_FULL ...\n",
            "\tFitting with cpus=1, gpus=0\n",
            "\t0.03s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: NeuralNetTorch_FULL ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.7 GB\n",
            "\t0.31s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMLarge_FULL ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.7 GB\n",
            "\t0.59s\t = Training   runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'NeuralNetFastAI': 0.833, 'CatBoost': 0.167}\n",
            "\t0.05s\t = Training   runtime\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
            "Refit complete, total runtime = 5.37s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
            "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_FULL ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.7 GB\n",
            "\t0.58s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBM_FULL ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.7 GB\n",
            "\t0.58s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: RandomForestGini_FULL ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.71s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: RandomForestEntr_FULL ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.9s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: CatBoost_FULL ...\n",
            "\tFitting with cpus=1, gpus=0\n",
            "\t0.08s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: ExtraTreesGini_FULL ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.78s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: ExtraTreesEntr_FULL ...\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.73s\t = Training   runtime\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: NeuralNetFastAI_FULL ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.6 GB\n",
            "\tStopping at the best epoch learned earlier - 17.\n",
            "\t0.53s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost_FULL ...\n",
            "\tFitting with cpus=1, gpus=0\n",
            "\t0.03s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: NeuralNetTorch_FULL ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.6 GB\n",
            "\t0.23s\t = Training   runtime\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMLarge_FULL ...\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/10.6 GB\n",
            "\t0.64s\t = Training   runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'XGBoost': 0.533, 'CatBoost': 0.267, 'NeuralNetTorch': 0.133, 'NeuralNetFastAI': 0.067}\n",
            "\t0.04s\t = Training   runtime\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
            "Refit complete, total runtime = 6.49s ... Best model: \"WeightedEnsemble_L2_FULL\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LightGBMXT': 'LightGBMXT_FULL',\n",
              " 'LightGBM': 'LightGBM_FULL',\n",
              " 'RandomForestGini': 'RandomForestGini_FULL',\n",
              " 'RandomForestEntr': 'RandomForestEntr_FULL',\n",
              " 'CatBoost': 'CatBoost_FULL',\n",
              " 'ExtraTreesGini': 'ExtraTreesGini_FULL',\n",
              " 'ExtraTreesEntr': 'ExtraTreesEntr_FULL',\n",
              " 'NeuralNetFastAI': 'NeuralNetFastAI_FULL',\n",
              " 'XGBoost': 'XGBoost_FULL',\n",
              " 'NeuralNetTorch': 'NeuralNetTorch_FULL',\n",
              " 'LightGBMLarge': 'LightGBMLarge_FULL',\n",
              " 'WeightedEnsemble_L2': 'WeightedEnsemble_L2_FULL'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we evaluate the models on the test datasets, and also show a leaderboard with a performance breakdown across all models trained during construction of the ensemble"
      ],
      "metadata": {
        "id": "SK_ggR0wCSDZ"
      },
      "id": "SK_ggR0wCSDZ"
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_hd.evaluate(hd_test)"
      ],
      "metadata": {
        "id": "d18jJcAnCY9x",
        "outputId": "cf9f8308-049c-45a9-a9ef-f10530d16d5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "d18jJcAnCY9x",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'roc_auc': np.float64(0.9222222222222223),\n",
              " 'accuracy': 0.8688524590163934,\n",
              " 'balanced_accuracy': np.float64(0.8827777777777778),\n",
              " 'mcc': np.float64(0.753106668091906),\n",
              " 'f1': 0.8571428571428571,\n",
              " 'precision': 0.7741935483870968,\n",
              " 'recall': 0.96}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_diabetes.evaluate(diabetes_test)"
      ],
      "metadata": {
        "id": "dkLOOE8uCvMe",
        "outputId": "89685667-ab1e-46ed-9782-18017a16c62a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dkLOOE8uCvMe",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'roc_auc': np.float64(0.8374824684431978),\n",
              " 'accuracy': 0.7532467532467533,\n",
              " 'balanced_accuracy': np.float64(0.7093267882187939),\n",
              " 'mcc': np.float64(0.4851234967443302),\n",
              " 'f1': 0.6122448979591837,\n",
              " 'precision': 0.8333333333333334,\n",
              " 'recall': 0.4838709677419355}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uwz1PvggDAT7"
      },
      "id": "Uwz1PvggDAT7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}